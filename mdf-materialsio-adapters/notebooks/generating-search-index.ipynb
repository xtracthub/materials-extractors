{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser Interface\n",
    "This notebook illustrates how to great MDF-ready metadata with MDF-MatIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdf_matio.adapters import noop_parsers\n",
    "from mdf_matio import get_mdf_parsers, generate_search_index\n",
    "from materials_io.utils import interface as matio\n",
    "from tarfile import TarFile\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Available Parsers\n",
    "The MDF only uses a limited subset of the data available via each parser.\n",
    "Consequently, the MDF interface to MaterialsIO only uses parsers for which we have defined this desired subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hyperspy_gui_traitsui:The module://ipykernel.pylab.backend_inline matplotlib backend is not compatible with the traitsui GUI elements. For more information, read http://hyperspy.readthedocs.io/en/stable/user_guide/getting_started.html#possible-warnings-when-importing-hyperspy.\n",
      "WARNING:hyperspy_gui_traitsui:The traitsui GUI elements are not available.\n",
      "c:\\users\\logan\\documents\\uc\\citrine\\software\\materials-io\\materials_io\\file.py:12: UserWarning: The libmagic library is not installed. See: https://github.com/ahupp/python-magic#installation\n",
      "  warn('The libmagic library is not installed. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 parsers: {'json', 'ase', 'em', 'crystal', 'noop', 'csv', 'dft', 'generic', 'image'}\n"
     ]
    }
   ],
   "source": [
    "all_parsers = matio.get_available_parsers()\n",
    "print(f'Found {len(all_parsers)} parsers:', set(all_parsers.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One part of the MDF IO library is defining which parsers produce data in this format or a method for transforming the outputs of the data into a format compatible with the MDF's Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 parsers that require zero alteration: ['image', 'em']\n"
     ]
    }
   ],
   "source": [
    "print(f'Found {len(noop_parsers)} parsers that require zero alteration:', noop_parsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 compatible parsers: {'json', 'em', 'csv', 'dft', 'generic', 'image'}\n"
     ]
    }
   ],
   "source": [
    "mdf_parsers = get_mdf_parsers()\n",
    "print(f'Found {len(mdf_parsers)} compatible parsers:', mdf_parsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these parsers require an \"adapter\" to transform the data into the MDF format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate Adapters\n",
    "A good example of a parser that generates data in a non-MDF format is the \"generic file parser.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = os.path.join('example-files', 'dog2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_parser = matio.get_parser('generic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generic parser produces the hashes for the data file and, if installed, autodetects the file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'length': 269360,\n",
       " 'filename': 'dog2.jpeg',\n",
       " 'path': 'example-files\\\\dog2.jpeg',\n",
       " 'sha512': '1f47ed450ad23e92caf1a0e5307e2af9b13edcd7735ac9685c9f21c9faec62cb95892e890a73480b06189ed5b842d8b265c5e47cc6cf279d281270211cff8f90'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_info = generic_parser.parse([test_file])\n",
    "file_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MDF search index stores this information under the the \"files\" block. \n",
    "Our adapter to the \"generic\" parser performs this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_adapter = matio.get_adapter('generic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': [{'length': 269360,\n",
       "   'filename': 'dog2.jpeg',\n",
       "   'path': 'example-files\\\\dog2.jpeg',\n",
       "   'sha512': '1f47ed450ad23e92caf1a0e5307e2af9b13edcd7735ac9685c9f21c9faec62cb95892e890a73480b06189ed5b842d8b265c5e47cc6cf279d281270211cff8f90',\n",
       "   'data_type': 'Unknown'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_adapter.transform(file_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of this adapter is that the MDF need not implement the hashing or file-type detection framework. \n",
    "The only tool needed for using this Materials IO parser is some data reshaping - a much easier task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing MDF-Compliant Data\n",
    "The `generate_search_index` function uses these capabilities to automatically generate compliant data from a directory of files.  It determines which parsers are available, runs them on all data in a directory, applies the adapters, and then merges the metadata of files records that describe the same record (e.g., a single experiment or calculation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking VASP data. (It is large enough that we do not want to commit the uncompressed files to GitHub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TarFile.open(os.path.join('example-files', 'calc', 'AlNi_static_LDA.tar.gz')) as t:\n",
    "    t.extractall(os.path.join('example-files', 'calc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying the search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generate_search_index at 0x000001FE4B45A9A8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_gen = generate_search_index(os.path.join('example-files'), False)\n",
    "record_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaterialsIO uses generators to avoid needing to hold the entire dataset in memory at once.\n",
    "Each metadata record is generated incremementally on-demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:2 parsers are not used: {'ase', 'crystal'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 records\n"
     ]
    }
   ],
   "source": [
    "records = list(record_gen)\n",
    "print(f'Generated {len(records)} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Results of Parsing\n",
    "There are 5 different records parsed from our example files.\n",
    "\n",
    "For simplicity, we just print the paths of files associated with each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_simple_paths(r):\n",
    "    return [f['path'] for f in r['files']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: ['group-by-dir\\\\other-dir\\\\dog3.jpeg']\n",
      "2: ['group-by-dir\\\\csv\\\\dog1.jpeg', 'group-by-dir\\\\csv\\\\test.csv']\n",
      "3: ['group-by-dir\\\\dog1.jpeg', 'group-by-dir\\\\dog2.jpeg', 'group-by-dir\\\\mdf.json']\n",
      "4: ['calc\\\\AlNi_static_LDA\\\\XDATCAR', 'calc\\\\AlNi_static_LDA\\\\POSCAR', 'calc\\\\AlNi_static_LDA\\\\OUTCAR', 'calc\\\\AlNi_static_LDA\\\\OSZICAR', 'calc\\\\AlNi_static_LDA\\\\KPOINTS', 'calc\\\\AlNi_static_LDA\\\\INCAR', 'calc\\\\AlNi_static_LDA\\\\DOSCAR', 'calc\\\\AlNi_static_LDA\\\\CONTCAR']\n",
      "5: ['dog2.jpeg']\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(records):\n",
    "    print(f'{i+1}:', print_simple_paths(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first record contains the several jpeg files that are grouped together.\n",
    "Normally, they are JPEGs are not grouped together.\n",
    "In this case the `mdf.json` file in that directory directs the parser to group records by directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"parse_by_directory\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('example-files', 'group-by-dir', 'mdf.json')) as fp:\n",
    "    print(fp.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration file applies to all subdirectories of `example-files/group-by-dir`\n",
    "\n",
    "The other record that contains $>1$ file includes all of the files from a VASP calcualtion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_records = [x for x in records if 'dft' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'files': [{'length': 292,\n",
       "    'filename': 'XDATCAR',\n",
       "    'path': 'calc\\\\AlNi_static_LDA\\\\XDATCAR',\n",
       "    'sha512': '5cc741db30247539aa75baa0510badd74e47d3fb966b0350d5d6914844222c9f4dc4b0d6bf9ae55bb04c0ed8e6b971ea522907e45b9c5bc942cd37c12be33056',\n",
       "    'data_type': 'Unknown'},\n",
       "   {'length': 189,\n",
       "    'filename': 'POSCAR',\n",
       "    'path': 'calc\\\\AlNi_static_LDA\\\\POSCAR',\n",
       "    'sha512': '180f5c5e1d273b3c069f40d67a3f57add75e617df6a5d11c7b3ccd78c3db3ce4378bbb7106e27c4f1b744ba9e6da3538aa1362f6a1b4102a47f317d5540e2aaf',\n",
       "    'data_type': 'Unknown'},\n",
       "   {'length': 266416,\n",
       "    'filename': 'OUTCAR',\n",
       "    'path': 'calc\\\\AlNi_static_LDA\\\\OUTCAR',\n",
       "    'sha512': 'cfcf0afc831204cb31354d7c03a8bc26cf4ac1c445afcc70dc336a19ed91338ab3d5f0556265dd50eb2bd18c7d4d69b1a882ee539de165ada6a3cfcae070a828',\n",
       "    'data_type': 'Unknown'},\n",
       "   {'length': 663,\n",
       "    'filename': 'OSZICAR',\n",
       "    'path': 'calc\\\\AlNi_static_LDA\\\\OSZICAR',\n",
       "    'sha512': 'daedbf1bc47695fb5fc4a65f0a8ae8b60a74d84fde9c569e3d957a5ae87ebf21e5bdd482ae69e9760e7b1125270ded62eb1d01af6882b83e4f42d12683b03a36',\n",
       "    'data_type': 'Unknown'},\n",
       "   {'length': 32,\n",
       "    'filename': 'KPOINTS',\n",
       "    'path': 'calc\\\\AlNi_static_LDA\\\\KPOINTS',\n",
       "    'sha512': '2a70cea721b10dd65c9d915ff18d906749380dead08d332dc15a2c6196c636b1bda4540377b6850a8cb4e689eca92e0889f9ee5f812d98b4f0078a591b9b19eb',\n",
       "    'data_type': 'Unknown'},\n",
       "   {'length': 460,\n",
       "    'filename': 'INCAR',\n",
       "    'path': 'calc\\\\AlNi_static_LDA\\\\INCAR',\n",
       "    'sha512': 'd1ece02baeedec07efa2cdaecee033c78a8e43886473e05fc1d3a3b8ebb0a32336214fa6713efbce9f4a331064b62b10dc9188c4d961a090d7e38529e6b04117',\n",
       "    'data_type': 'Unknown'},\n",
       "   {'length': 18297,\n",
       "    'filename': 'DOSCAR',\n",
       "    'path': 'calc\\\\AlNi_static_LDA\\\\DOSCAR',\n",
       "    'sha512': 'defdb049f871123ae2fe93adc3e7a1834f236ac771f10e82b75bdc74f80eaffb7dfe395caeac2fc145df961bffddbabc1dd6e7c57399c7c03d94fb8e078ae2e7',\n",
       "    'data_type': 'Unknown'},\n",
       "   {'length': 523,\n",
       "    'filename': 'CONTCAR',\n",
       "    'path': 'calc\\\\AlNi_static_LDA\\\\CONTCAR',\n",
       "    'sha512': 'b29f1e6ced5bb681bf0ab19e264e0d182581fd8a84e47d20eb9c323791f0fe3e87a460c6c964dbcce971556c30860a4a141795c671ced3eb8c4d95528d128383',\n",
       "    'data_type': 'Unknown'}],\n",
       "  'material': {'elemental_proportions': {'Al': 1}},\n",
       "  'dft': {'converged': True,\n",
       "   'exchange_correlation_functional': 'PAW',\n",
       "   'cutoff_energy': 650.0},\n",
       "  'origin': {'type': 'computation', 'name': 'VASP', 'version': '5.3.2'}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how this record contains >1 file and additional metadata for the DFT calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Mappings\n",
    "The MDF Connect pipeline allows for users to specify which fields in certain types of files can be mapped to known fields in the MDF.\n",
    "These instructions are included in the `index` field of a submission and our `generate_search_index` function takes this field without modification to define the mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing = {\n",
    "    'csv': {'mapping': {'material.composition': 'composition'}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:2 parsers are not used: {'ase', 'crystal'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 7 records\n"
     ]
    }
   ],
   "source": [
    "records = list(generate_search_index(os.path.join('example-files'), False, index_options=indexing))\n",
    "print(f'Created {len(records)} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we created more records this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: ['group-by-dir\\\\other-dir\\\\dog3.jpeg']\n",
      "2: ['group-by-dir\\\\csv\\\\dog1.jpeg', 'group-by-dir\\\\csv\\\\test.csv']\n",
      "3: ['group-by-dir\\\\dog1.jpeg', 'group-by-dir\\\\dog2.jpeg', 'group-by-dir\\\\mdf.json']\n",
      "4: ['calc\\\\AlNi_static_LDA\\\\XDATCAR', 'calc\\\\AlNi_static_LDA\\\\POSCAR', 'calc\\\\AlNi_static_LDA\\\\OUTCAR', 'calc\\\\AlNi_static_LDA\\\\OSZICAR', 'calc\\\\AlNi_static_LDA\\\\KPOINTS', 'calc\\\\AlNi_static_LDA\\\\INCAR', 'calc\\\\AlNi_static_LDA\\\\DOSCAR', 'calc\\\\AlNi_static_LDA\\\\CONTCAR']\n",
      "5: ['test.csv']\n",
      "6: ['test.csv']\n",
      "7: ['dog2.jpeg']\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(records):\n",
    "    print(f'{i+1}:', print_simple_paths(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the the `test.csv` file appears twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "composition,data\n",
      "NaCl,4\n",
      "LiFePO4,-1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('example-files', 'test.csv')) as fp:\n",
    "    print(fp.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because `test.csv` contains 2 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'material': {'composition': 'NaCl'},\n",
       "  'files': [{'length': 38,\n",
       "    'filename': 'test.csv',\n",
       "    'path': 'test.csv',\n",
       "    'sha512': 'c436c80612a7ac63545f10099aa0453238afe6d708c8606594d6bbceed46a3d6c956a62340851ff93452d5060791925530d145a8a4526ef893d51a010bcf141a',\n",
       "    'data_type': 'Unknown'}]},\n",
       " {'material': {'composition': 'LiFePO4'},\n",
       "  'files': [{'length': 38,\n",
       "    'filename': 'test.csv',\n",
       "    'path': 'test.csv',\n",
       "    'sha512': 'c436c80612a7ac63545f10099aa0453238afe6d708c8606594d6bbceed46a3d6c956a62340851ff93452d5060791925530d145a8a4526ef893d51a010bcf141a',\n",
       "    'data_type': 'Unknown'}]}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r for r in records if r['files'][0]['path'] == 'test.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As desired, the mapping we defined maps the data in the composition column into `materials.composition` and\n",
    "there is one record per entry in the CSV file.\n",
    "\n",
    "The `mdf_matio` adapter will also merge the metadata records produced for CSV files with those from other files.\n",
    "An example is merging files in a directory that contains a CSV file and an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_csv = [r for r in records if r['files'][0]['path'] == os.path.join('group-by-dir', 'csv', 'dog1.jpeg')][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['group-by-dir\\\\csv\\\\dog1.jpeg', 'group-by-dir\\\\csv\\\\test.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_simple_paths(merged_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the metadata from all other files are merged into the metadata of each records from the CSV file.\n",
    "This CSV file happens to have only 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'material': {'composition': 'NaCl'},\n",
       " 'files': [{'length': 269360,\n",
       "   'filename': 'dog1.jpeg',\n",
       "   'path': 'group-by-dir\\\\csv\\\\dog1.jpeg',\n",
       "   'sha512': '1f47ed450ad23e92caf1a0e5307e2af9b13edcd7735ac9685c9f21c9faec62cb95892e890a73480b06189ed5b842d8b265c5e47cc6cf279d281270211cff8f90',\n",
       "   'data_type': 'Unknown'},\n",
       "  {'length': 26,\n",
       "   'filename': 'test.csv',\n",
       "   'path': 'group-by-dir\\\\csv\\\\test.csv',\n",
       "   'sha512': 'a6080a499a7fc72f103cc72352b30d6abd87d6eca4bcda7c792fa5a0d90c2834b68ab8ed425f736193a57ee21489581205eb72f17143363bb8ae3a68893fe959',\n",
       "   'data_type': 'Unknown'}],\n",
       " 'image': {'width': 1910,\n",
       "  'height': 1000,\n",
       "  'format': 'JPEG',\n",
       "  'megapixels': 1.91}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Files\n",
    "Like CSV files, JSON files require a mapping in order to be parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:2 parsers are not used: {'ase', 'crystal'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 0 records\n"
     ]
    }
   ],
   "source": [
    "records = list(generate_search_index(os.path.join('example-files', 'json'), False, index_options=indexing))\n",
    "print(f'Created {len(records)} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we define our mapping following the same schema as the MDF Connect request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing = {\n",
    "    'json': {\n",
    "        'mapping': {'material.composition': 'composition', 'value': 'oqmd.delta_e'},\n",
    "        'na_values': 'N/A'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:2 parsers are not used: {'ase', 'crystal'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 records\n"
     ]
    }
   ],
   "source": [
    "records = list(generate_search_index(os.path.join('example-files', 'json'), False, index_options=indexing))\n",
    "print(f'Created {len(records)} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: ['line-delimited.json']\n",
      "2: ['line-delimited.json']\n",
      "3: ['list.json']\n",
      "4: ['list.json']\n",
      "5: ['simple.json']\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(records):\n",
    "    print(f'{i+1}:', print_simple_paths(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first case of a JSON file is one where we have a single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"composition\": \"CuZr\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_file = os.path.join('example-files', 'json', 'simple.json')\n",
    "with open(list_file) as fp:\n",
    "    print(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'material': {'composition': 'CuZr'},\n",
       "  'files': [{'length': 25,\n",
       "    'filename': 'simple.json',\n",
       "    'path': 'simple.json',\n",
       "    'sha512': 'af52bc1609a6a09851646a2524b1044f576c676a396a6dd1b0add67c83355c738a016dd0d5d4d9094e55cb34cdd9115d640fd1219278e718069df31ed0f6b3de',\n",
       "    'data_type': 'Unknown'}]}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r for r in records if 'simple' in r['files'][0]['path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the mapping creates a single new record\n",
    "\n",
    "Another option is for a JSON file to contain a list of multiple objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"composition\": \"CuZr\", \"oqmd\": {\"delta_e\": \"N/A\"}},\n",
      "  {\"composition\": \"Fe\", \"oqmd\": {\"delta_e\": 0}}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_file = os.path.join('example-files', 'json', 'list.json')\n",
    "with open(list_file) as fp:\n",
    "    print(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'material': {'composition': 'CuZr'},\n",
       "  'files': [{'length': 105,\n",
       "    'filename': 'list.json',\n",
       "    'path': 'list.json',\n",
       "    'sha512': '76f47619866e91da239aaa10bee41835e686392fe7d940e458f154d9c33701a4621ddafd13744354f6e5ccd0199a7f96cb37ef2f3f53cee408589e84ffd092c5',\n",
       "    'data_type': 'Unknown'}]},\n",
       " {'material': {'composition': 'Fe'},\n",
       "  'value': 0,\n",
       "  'files': [{'length': 105,\n",
       "    'filename': 'list.json',\n",
       "    'path': 'list.json',\n",
       "    'sha512': '76f47619866e91da239aaa10bee41835e686392fe7d940e458f154d9c33701a4621ddafd13744354f6e5ccd0199a7f96cb37ef2f3f53cee408589e84ffd092c5',\n",
       "    'data_type': 'Unknown'}]}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r for r in records if 'list' in r['files'][0]['path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the parser and adapter recognize that the file contains multiple records.\n",
    "Note that the `na_values` command in the indexing removes the missing value value from the first record.\n",
    "\n",
    "Finally, the JSON parser also supports reading multiple records from line-delimited JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"composition\": \"NaCl\"}\n",
      "{\"composition\":  \"LiFePO4\"}\n",
      "{}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_file = os.path.join('example-files', 'json', 'line-delimited.json')\n",
    "with open(list_file) as fp:\n",
    "    print(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'material': {'composition': 'NaCl'},\n",
       "  'files': [{'length': 58,\n",
       "    'filename': 'line-delimited.json',\n",
       "    'path': 'line-delimited.json',\n",
       "    'sha512': '7a450a893c60b1110dd6085f5b52661482249af3352a123b5660b5dffeb5550bf285755da65c4c589c70abdf6820d3a8061a2733f0c6a8af5f620228412856fd',\n",
       "    'data_type': 'Unknown'}]},\n",
       " {'material': {'composition': 'LiFePO4'},\n",
       "  'files': [{'length': 58,\n",
       "    'filename': 'line-delimited.json',\n",
       "    'path': 'line-delimited.json',\n",
       "    'sha512': '7a450a893c60b1110dd6085f5b52661482249af3352a123b5660b5dffeb5550bf285755da65c4c589c70abdf6820d3a8061a2733f0c6a8af5f620228412856fd',\n",
       "    'data_type': 'Unknown'}]}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r for r in records if 'line-' in r['files'][0]['path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how it reads multiple records and skips the last line that does not match any mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
